"""
å®Œæ•´çš„é›†æˆç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨agno_modularè¿›è¡Œå¤šå‚å•†é€‚é…ã€æµå¼å¯¹è¯å’ŒWebSocketé›†æˆ
"""

import asyncio
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

# å¯¼å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡å—
from multi_provider_adapter import (
    MultiProviderManager, ProviderConfig, ProviderType,
    register_openai_provider, register_anthropic_provider, register_agno_provider
)
from streaming_chat import StreamingChatManager, StreamFormat
from streaming_generator import (
    StreamingGeneratorFactory, GeneratorMode, streaming_context
)
from websocket_integration import (
    WebSocketManager, WebSocketMessage, WebSocketMessageType
)
from agent_manager import AgentCRUDManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MultiProviderStreamingIntegration:
    """å¤šå‚å•†æµå¼å¯¹è¯é›†æˆç¤ºä¾‹"""

    def __init__(self):
        self.provider_manager = MultiProviderManager()
        self.streaming_manager = StreamingChatManager(self.provider_manager)
        self.websocket_manager = None  # å°†åœ¨éœ€è¦æ—¶åˆ›å»º
        self.agent_manager = None  # å°†åœ¨éœ€è¦æ—¶åˆ›å»º

    async def initialize_providers(self):
        """åˆå§‹åŒ–å¤šä¸ªAIå‚å•†"""
        logger.info("Initializing AI providers...")

        # æ³¨å†ŒOpenAIæä¾›å•†
        openai_success = await register_openai_provider(
            provider_id="openai_gpt35",
            api_key="your-openai-api-key",  # æ›¿æ¢ä¸ºå®é™…çš„APIå¯†é’¥
            model_name="gpt-3.5-turbo",
            max_tokens=2000,
            temperature=0.7
        )
        logger.info(f"OpenAI provider registration: {'Success' if openai_success else 'Failed'}")

        # æ³¨å†ŒAnthropicæä¾›å•†
        anthropic_success = await register_anthropic_provider(
            provider_id="anthropic_claude",
            api_key="your-anthropic-api-key",  # æ›¿æ¢ä¸ºå®é™…çš„APIå¯†é’¥
            model_name="claude-3-sonnet-20240229",
            max_tokens=2000,
            temperature=0.5
        )
        logger.info(f"Anthropic provider registration: {'Success' if anthropic_success else 'Failed'}")

        # æ³¨å†ŒAgnoåŸç”Ÿæä¾›å•†
        agno_success = await register_agno_provider(
            provider_id="agno_native",
            model_name="qwen3-vl-4b-instruct",
            max_tokens=2048,
            temperature=0.8,
            supports_streaming=True,
            supports_tools=True
        )
        logger.info(f"Agno provider registration: {'Success' if agno_success else 'Failed'}")

        # è®¾ç½®é»˜è®¤æä¾›å•†
        if openai_success:
            self.provider_manager.set_default_provider("openai_gpt35")

        # æ£€æŸ¥æ‰€æœ‰æä¾›å•†çš„å¥åº·çŠ¶æ€
        health_status = await self.provider_manager.health_check_all()
        logger.info("Provider health status:")
        for provider_id, status in health_status.items():
            logger.info(f"  {provider_id}: {status['status']}")

    async def basic_streaming_example(self):
        """åŸºç¡€æµå¼å¯¹è¯ç¤ºä¾‹"""
        logger.info("\n=== Basic Streaming Example ===")

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "è¯·ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²ã€‚"}
        ]

        # ä½¿ç”¨é»˜è®¤æä¾›å•†è¿›è¡Œæµå¼å¯¹è¯
        logger.info("Starting streaming chat with default provider...")
        response_text = ""

        async for chunk in self.streaming_manager.create_session().stream_chat(
            messages=messages,
            stream_format=StreamFormat.SSE
        ):
            if chunk.startswith("data: "):
                try:
                    data = json.loads(chunk[6:])  # ç§»é™¤ "data: " å‰ç¼€
                    if data.get("type") == "text-delta":
                        content = data.get("content", "")
                        response_text += content
                        print(content, end="", flush=True)
                    elif data.get("type") == "finish":
                        print("\n\nStreaming completed!")
                        break
                except json.JSONDecodeError:
                    continue

        logger.info(f"Full response length: {len(response_text)} characters")

    async def multi_provider_comparison(self):
        """å¤šå‚å•†å¯¹æ¯”ç¤ºä¾‹"""
        logger.info("\n=== Multi-Provider Comparison Example ===")

        messages = [
            {"role": "user", "content": "è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‚"}
        ]

        providers = ["openai_gpt35", "anthropic_claude", "agno_native"]
        results = {}

        for provider_id in providers:
            try:
                logger.info(f"Testing provider: {provider_id}")
                response_text = ""

                async for chunk in self.streaming_manager.create_session().stream_chat(
                    messages=messages,
                    provider_id=provider_id,
                    stream_format=StreamFormat.SSE
                ):
                    if chunk.startswith("data: "):
                        try:
                            data = json.loads(chunk[6:])
                            if data.get("type") == "text-delta":
                                response_text += data.get("content", "")
                        except json.JSONDecodeError:
                            continue

                results[provider_id] = response_text
                logger.info(f"Provider {provider_id} response length: {len(response_text)}")

            except Exception as e:
                logger.error(f"Provider {provider_id} error: {e}")
                results[provider_id] = f"Error: {str(e)}"

        # è¾“å‡ºå¯¹æ¯”ç»“æœ
        logger.info("\n=== Provider Comparison Results ===")
        for provider_id, response in results.items():
            logger.info(f"\n{provider_id}:")
            logger.info(f"  Length: {len(response)} characters")
            logger.info(f"  Preview: {response[:200]}...")

    async def advanced_generator_modes(self):
        """é«˜çº§ç”Ÿæˆå™¨æ¨¡å¼ç¤ºä¾‹"""
        logger.info("\n=== Advanced Generator Modes Example ===")

        messages = [
            {"role": "user", "content": "å†™ä¸€ä¸ªç®€çŸ­çš„æ•…äº‹ï¼ŒåŒ…å«ä»¥ä¸‹å…ƒç´ ï¼šå†’é™©ã€é­”æ³•ã€å‹è°Š"}
        ]

        # æ ‡å‡†æ¨¡å¼
        logger.info("1. Standard mode:")
        async with streaming_context(GeneratorMode.STANDARD) as generator:
            async for event in generator.generate(messages):
                if event.event_type.value == "text-delta":
                    print(event.data.get("content", ""), end="", flush=True)
        print("\n")

        # ç¼“å†²æ¨¡å¼
        logger.info("2. Buffered mode:")
        from streaming_generator import GeneratorConfig
        config = GeneratorConfig(
            mode=GeneratorMode.BUFFERED,
            buffer_size=50,  # ç¼“å†²50ä¸ªå­—ç¬¦
            flush_interval=0.2  # æ¯0.2ç§’åˆ·æ–°ä¸€æ¬¡
        )

        async with streaming_context(GeneratorMode.BUFFERED, config) as generator:
            async for event in generator.generate(messages):
                if event.event_type.value == "text-delta":
                    print(event.data.get("content", ""), end="", flush=True)
        print("\n")

        # åˆ†å—æ¨¡å¼
        logger.info("3. Chunked mode:")
        chunk_config = GeneratorConfig(
            mode=GeneratorMode.CHUNKED,
            chunk_size=100  # æ¯100ä¸ªå­—ç¬¦ä¸ºä¸€å—
        )

        async with streaming_context(GeneratorMode.CHUNKED, chunk_config) as generator:
            chunk_count = 0
            async for event in generator.generate(messages):
                if event.event_type.value == "text-delta":
                    chunk_count += 1
                    content = event.data.get("content", "")
                    print(f"Chunk {chunk_count}: {content}")
        print("\n")

    async def websocket_simulation(self):
        """WebSocketæ¨¡æ‹Ÿç¤ºä¾‹"""
        logger.info("\n=== WebSocket Simulation Example ===")

        # åˆ›å»ºWebSocketç®¡ç†å™¨
        self.websocket_manager = WebSocketManager(
            self.streaming_manager,
            self.provider_manager
        )

        # æ¨¡æ‹ŸWebSocketè¿æ¥
        class MockWebSocket:
            def __init__(self):
                self.messages = []
                self.closed = False

            async def accept(self):
                pass

            async def send_text(self, message: str):
                self.messages.append(message)
                # æ¨¡æ‹Ÿå¤„ç†æ¶ˆæ¯
                try:
                    data = json.loads(message)
                    if data.get("message_type") == "stream_event":
                        event_data = data.get("data", {})
                        if event_data.get("event_type") == "text-delta":
                            content = event_data.get("event_data", {}).get("content", "")
                            print(content, end="", flush=True)
                except:
                    pass

            async def receive_text(self):
                # æ¨¡æ‹Ÿæ¥æ”¶èŠå¤©è¯·æ±‚
                return json.dumps({
                    "message_type": "chat_request",
                    "data": {
                        "messages": [
                            {"role": "user", "content": "ç”¨WebSocketå‘é€æ¶ˆæ¯çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"}
                        ],
                        "generator_mode": "standard"
                    }
                })

            async def close(self):
                self.closed = True

        # åˆ›å»ºæ¨¡æ‹Ÿè¿æ¥
        mock_websocket = MockWebSocket()
        connection = await self.websocket_manager.add_connection(
            websocket=mock_websocket,
            user_id="test_user",
            session_id="test_session"
        )

        logger.info(f"Created mock connection: {connection.connection_id}")

        # å¤„ç†æ¶ˆæ¯
        print("WebSocket response: ", end="", flush=True)
        await self.websocket_manager.handle_connection(connection.connection_id)
        print("\n")

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.websocket_manager.get_statistics()
        logger.info(f"WebSocket statistics: {stats}")

    async def agent_integration_example(self):
        """Agenté›†æˆç¤ºä¾‹"""
        logger.info("\n=== Agent Integration Example ===")

        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„æ•°æ®åº“è¿æ¥å’ŒAgentç®¡ç†å™¨
        # ä»¥ä¸‹ä»£ç ä¸ºæ¨¡æ‹Ÿç¤ºä¾‹
        try:
            # æ¨¡æ‹Ÿåˆ›å»ºAgent
            agent_id = 1  # å‡è®¾è¿™æ˜¯å·²å­˜åœ¨çš„Agent ID

            messages = [
                {"role": "user", "content": "ä½œä¸ºä¸€ä¸ªPythonåŠ©æ‰‹ï¼Œè¯·è§£é‡Šä»€ä¹ˆæ˜¯è£…é¥°å™¨"}
            ]

            logger.info(f"Running agent {agent_id} with streaming...")

            # ä½¿ç”¨Agentè¿›è¡Œæµå¼å¯¹è¯
            response_text = ""
            async for chunk in self.streaming_manager.stream_chat_with_agent(
                agent_id=agent_id,
                message=messages[0]["content"],
                stream_format=StreamFormat.SSE
            ):
                if chunk.startswith("data: "):
                    try:
                        data = json.loads(chunk[6:])
                        if data.get("type") == "text-delta":
                            content = data.get("content", "")
                            response_text += content
                            print(content, end="", flush=True)
                        elif data.get("type") == "finish":
                            print("\n\nAgent streaming completed!")
                            break
                    except json.JSONDecodeError:
                        continue

            logger.info(f"Agent response length: {len(response_text)} characters")

        except Exception as e:
            logger.error(f"Agent integration error: {e}")
            logger.info("Note: Agent integration requires proper database setup")

    async def performance_test(self):
        """æ€§èƒ½æµ‹è¯•"""
        logger.info("\n=== Performance Test Example ===")

        messages = [
            {"role": "user", "content": "ç®€å•å›ç­”ï¼š1+1ç­‰äºå¤šå°‘ï¼Ÿ"}
        ]

        # æµ‹è¯•ä¸åŒæä¾›å•†çš„å“åº”æ—¶é—´
        providers = ["openai_gpt35", "anthropic_claude", "agno_native"]
        performance_results = {}

        for provider_id in providers:
            try:
                start_time = datetime.now()
                response_text = ""
                events_processed = 0

                async for chunk in self.streaming_manager.create_session().stream_chat(
                    messages=messages,
                    provider_id=provider_id,
                    stream_format=StreamFormat.SSE
                ):
                    if chunk.startswith("data: "):
                        try:
                            data = json.loads(chunk[6:])
                            events_processed += 1
                            if data.get("type") == "text-delta":
                                response_text += data.get("content", "")
                        except json.JSONDecodeError:
                            continue

                end_time = datetime.now()
                response_time = (end_time - start_time).total_seconds()

                performance_results[provider_id] = {
                    "response_time": response_time,
                    "events_processed": events_processed,
                    "response_length": len(response_text),
                    "events_per_second": events_processed / response_time if response_time > 0 else 0
                }

            except Exception as e:
                performance_results[provider_id] = {"error": str(e)}

        # è¾“å‡ºæ€§èƒ½ç»“æœ
        logger.info("Performance Test Results:")
        for provider_id, result in performance_results.items():
            if "error" in result:
                logger.info(f"  {provider_id}: Error - {result['error']}")
            else:
                logger.info(f"  {provider_id}:")
                logger.info(f"    Response time: {result['response_time']:.2f}s")
                logger.info(f"    Events processed: {result['events_processed']}")
                logger.info(f"    Response length: {result['response_length']}")
                logger.info(f"    Events/sec: {result['events_per_second']:.2f}")

    async def error_handling_example(self):
        """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
        logger.info("\n=== Error Handling Example ===")

        messages = [
            {"role": "user", "content": "æµ‹è¯•é”™è¯¯å¤„ç†"}
        ]

        # æµ‹è¯•æ— æ•ˆæä¾›å•†
        logger.info("1. Testing invalid provider:")
        try:
            async for chunk in self.streaming_manager.create_session().stream_chat(
                messages=messages,
                provider_id="invalid_provider",
                stream_format=StreamFormat.SSE
            ):
                if chunk.startswith("data: "):
                    try:
                        data = json.loads(chunk[6:])
                        if data.get("type") == "error":
                            logger.info(f"Received error: {data.get('data', {}).get('error')}")
                            break
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            logger.info(f"Caught exception: {e}")

        # æµ‹è¯•ç©ºæ¶ˆæ¯
        logger.info("2. Testing empty messages:")
        try:
            async for chunk in self.streaming_manager.create_session().stream_chat(
                messages=[],
                stream_format=StreamFormat.SSE
            ):
                pass
        except Exception as e:
            logger.info(f"Caught exception for empty messages: {e}")

    async def run_all_examples(self):
        """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
        logger.info("ğŸš€ Starting Multi-Provider Streaming Integration Examples")

        try:
            # åˆå§‹åŒ–æä¾›å•†
            await self.initialize_providers()

            # è¿è¡Œå„ç§ç¤ºä¾‹
            await self.basic_streaming_example()
            await self.multi_provider_comparison()
            await self.advanced_generator_modes()
            await self.websocket_simulation()
            await self.agent_integration_example()
            await self.performance_test()
            await self.error_handling_example()

            logger.info("âœ… All examples completed successfully!")

        except Exception as e:
            logger.error(f"âŒ Example execution failed: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    integration = MultiProviderStreamingIntegration()
    await integration.run_all_examples()


if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(main())