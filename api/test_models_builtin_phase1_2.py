"""
Phase 1.2 æµ‹è¯•: MLX-VLM Server è¿›ç¨‹ç®¡ç†
æµ‹è¯•å†…å®¹ï¼š
1. å¯åŠ¨æœåŠ¡å™¨
2. å¥åº·æ£€æŸ¥
3. æœåŠ¡å™¨çŠ¶æ€æŸ¥è¯¢
4. åœæ­¢æœåŠ¡å™¨
"""

import sys
import time
import logging
from pathlib import Path
from models_builtin import ModelsBuiltin
import httpx
from sqlmodel import create_engine
from config import TEST_DB_PATH, VLM_MODEL

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_server_lifecycle():
    """æµ‹è¯•æœåŠ¡å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    print("\n" + "="*60)
    print("Phase 1.2 æµ‹è¯•: MLX-VLM Server è¿›ç¨‹ç®¡ç†")
    print("="*60)
    
    # åˆå§‹åŒ–
    engine = create_engine(f'sqlite:///{TEST_DB_PATH}')
    base_dir = Path(TEST_DB_PATH).parent.as_posix()
    models_builtin = ModelsBuiltin(engine, base_dir)
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
    model_id = "qwen3-vl-4b"
    print(f"\n1. æ£€æŸ¥æ¨¡å‹ {model_id} æ˜¯å¦å·²ä¸‹è½½...")
    
    if not models_builtin.is_model_downloaded(model_id):
        print(f"âŒ æ¨¡å‹ {model_id} æœªä¸‹è½½ï¼Œè¯·å…ˆè¿è¡Œ test_models_builtin_phase1_3.py")
        return False
    
    model_path = models_builtin.get_model_path(model_id)
    print(f"âœ… æ¨¡å‹å·²ä¸‹è½½: {model_path}")
    
    # æµ‹è¯•åˆå§‹çŠ¶æ€
    print("\n2. æ£€æŸ¥åˆå§‹æœåŠ¡å™¨çŠ¶æ€...")
    initial_status = models_builtin.get_server_status()
    print(f"   - Running: {initial_status['running']}")
    print(f"   - URL: {initial_status['url']}")
    
    if initial_status['running']:
        print("âš ï¸  æœåŠ¡å™¨å·²åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢...")
        models_builtin.stop_mlx_server()
        time.sleep(2)
    
    # æµ‹è¯•å¯åŠ¨æœåŠ¡å™¨
    print("\n3. å¯åŠ¨ MLX-VLM æœåŠ¡å™¨...")
    print(f"   æ¨¡å‹: {model_id}")
    print("   åœ°å€: http://127.0.0.1:60316")
    print("   (è¿™å¯èƒ½éœ€è¦ 30-60 ç§’ï¼Œå› ä¸ºéœ€è¦åŠ è½½æ¨¡å‹...)")
    
    start_success = models_builtin.start_mlx_server(model_id)
    
    if not start_success:
        print("âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥")
        return False
    
    print("âœ… æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ")
    
    # æµ‹è¯•å¥åº·æ£€æŸ¥
    print("\n4. æ‰§è¡Œå¥åº·æ£€æŸ¥...")
    is_healthy = models_builtin.health_check()
    print(f"   å¥åº·çŠ¶æ€: {'âœ… æ­£å¸¸' if is_healthy else 'âŒ å¼‚å¸¸'}")
    
    if not is_healthy:
        print("âŒ å¥åº·æ£€æŸ¥å¤±è´¥")
        models_builtin.stop_mlx_server()
        return False
    
    # æµ‹è¯•æœåŠ¡å™¨çŠ¶æ€
    print("\n5. æŸ¥è¯¢æœåŠ¡å™¨è¯¦ç»†çŠ¶æ€...")
    status = models_builtin.get_server_status()
    print(f"   - Running: {status['running']}")
    print(f"   - PID: {status['process_id']}")
    print(f"   - Loaded Model: {status.get('loaded_model', 'N/A')}")
    print(f"   - URL: {status['url']}")
    
    # æµ‹è¯• API è°ƒç”¨ï¼ˆç®€å•çš„å¥åº·æ£€æŸ¥ï¼‰
    print("\n6. æµ‹è¯• API ç«¯ç‚¹...")
    try:
        # æµ‹è¯• /health ç«¯ç‚¹
        with httpx.Client(timeout=10.0) as client:
            response = client.get("http://127.0.0.1:60316/health")
            if response.status_code == 200:
                health_data = response.json()
                print("   âœ… /health ç«¯ç‚¹å“åº”æ­£å¸¸")
                print(f"      Loaded model: {health_data.get('loaded_model')}")
            else:
                print(f"   âŒ /health ç«¯ç‚¹å“åº”å¼‚å¸¸: {response.status_code}")
    except Exception as e:
        print(f"   âŒ API è°ƒç”¨å¤±è´¥: {e}")
    
    # æµ‹è¯•çœŸå®çš„è§†è§‰é—®ç­”
    print("\n7. æµ‹è¯•çœŸå®çš„è§†è§‰é—®ç­”åŠŸèƒ½...")
    print("   (ä½¿ç”¨ OpenAI-compatible /responses ç«¯ç‚¹)")
    try:
        # ä½¿ç”¨ä¸€ä¸ªå…¬å¼€çš„æµ‹è¯•å›¾ç‰‡
        test_image_url = "/Users/dio/Downloads/Gvk2MmNaMAAxNnJ.jpeg"
        test_prompt = "Describe this image in one sentence."
        
        with httpx.Client(timeout=30.0) as client:
            # ä½¿ç”¨ /responses ç«¯ç‚¹ (OpenAI-compatible)
            response = client.post(
                "http://127.0.0.1:60316/responses",
                headers={"Content-Type": "application/json"},
                json={
                    "model": VLM_MODEL,
                    "input": [
                        {
                            "role": "user",
                            "content": [
                                {"type": "input_text", "text": test_prompt},
                                {"type": "input_image", "image_url": test_image_url}
                            ]
                        }
                    ],
                    "max_output_tokens": 100,
                    "temperature": 0.7
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                # æå–ç”Ÿæˆçš„æ–‡æœ¬
                output_text = result.get("output_text", "")
                if not output_text and result.get("output"):
                    # å°è¯•ä» output æ•°ç»„ä¸­æå–
                    for item in result.get("output", []):
                        if isinstance(item, dict) and "content" in item:
                            content = item["content"]
                            if isinstance(content, list) and len(content) > 0:
                                output_text = content[0].get("text", "")
                                break
                
                print("   âœ… è§†è§‰é—®ç­”æµ‹è¯•æˆåŠŸ")
                print(f"   ğŸ“ é—®é¢˜: {test_prompt}")
                print(f"   ğŸ–¼ï¸  å›¾ç‰‡: {test_image_url}")
                print(f"   ğŸ’¬ å›ç­”: {output_text[:200]}...")  # åªæ˜¾ç¤ºå‰200å­—ç¬¦
                
                # æ£€æŸ¥ token ä½¿ç”¨æƒ…å†µ
                usage = result.get("usage", {})
                if usage:
                    print(f"   ğŸ“Š Token ä½¿ç”¨: input={usage.get('input_tokens')}, output={usage.get('output_tokens')}")
            else:
                print(f"   âŒ è§†è§‰é—®ç­”å¤±è´¥: HTTP {response.status_code}")
                print(f"      å“åº”: {response.text[:200]}")
                
    except Exception as e:
        print(f"   âš ï¸  è§†è§‰é—®ç­”æµ‹è¯•å‡ºé”™: {e}")
        print("      (è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå–å†³äºç½‘ç»œå’Œæ¨¡å‹çŠ¶æ€)")
    
    # æµ‹è¯•åœæ­¢æœåŠ¡å™¨
    print("\n8. åœæ­¢æœåŠ¡å™¨...")
    stop_success = models_builtin.stop_mlx_server()
    
    if not stop_success:
        print("âŒ æœåŠ¡å™¨åœæ­¢å¤±è´¥")
        return False
    
    print("âœ… æœåŠ¡å™¨å·²åœæ­¢")
    
    # éªŒè¯æœåŠ¡å™¨å·²åœæ­¢
    print("\n9. éªŒè¯æœåŠ¡å™¨å·²åœæ­¢...")
    time.sleep(2)
    final_status = models_builtin.get_server_status()
    
    if final_status['running']:
        print("âŒ æœåŠ¡å™¨ä»åœ¨è¿è¡Œ")
        return False
    
    print("âœ… æœåŠ¡å™¨ç¡®è®¤å·²åœæ­¢")
    
    print("\n" + "="*60)
    print("âœ… Phase 1.2 æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("="*60)
    
    return True


if __name__ == "__main__":
    try:
        success = test_server_lifecycle()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        sys.exit(1)
