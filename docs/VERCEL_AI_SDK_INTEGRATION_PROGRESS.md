# Vercel AI SDK v5 聊天界面集成 - 进度跟踪文档

> **项目目标**：基于产品设计文档(PRD.md)，实现聊天界面与Vercel AI SDK v5的深度集成，建立完整的对话状态管理和会话持久化系统。

## 🏗️ 整体技术架构

```text
前端TypeScript + AI SDK v5 ← Tauri IPC → Rust Bridge ← HTTP → Python FastAPI
    ↓                                                                ↓
自定义Transport(Tauri HTTP)                                    SSE兼容流式响应
    ↓                                                                ↓  
UIMessage状态管理                                               UIMessage生成
    ↓                                                                ↓
会话持久化存储                                               消息数据库存储
    ↓                                                                ↓
智能上下文管理                                               动态token截断
```

## 🎯 核心设计原则

### 数据流和状态管理

- **UIMessage格式**：前端状态管理和持久化的唯一数据源
- **会话隔离**：每个会话独立的pin文件列表和聊天记录
- **动态上下文**：根据token限制智能截断历史消息
- **智能降级**：在线模型 → 本地模型的无缝降级策略

### 用户体验原则

- **流式加载**：聊天记录分页加载，最近30条优先显示
- **状态感知**：用户能清楚感知当前使用的模型类型（在线/本地）
- **无缝切换**：会话切换时完整恢复pin文件列表和聊天上下文
- **渐进增强**：先实现基础功能，为RAG集成预留扩展空间

---

## 🎯 第一阶段：技术验证与环境适配（P0 - 必须完成）

**目标**：验证Vercel AI SDK v5在Tauri环境中的可行性，解决核心技术风险

### 1.1 环境适配验证（风险1解决）

- [x] **1.1.1 AI SDK v5安装和基础配置**
  - [x] 在tauri-app中安装`ai@beta`、`@ai-sdk/react@beta`包
  - [x] 创建基础的useChat配置demo，验证TypeScript类型
  - [x] 测试AI SDK v5的基础功能（UIMessage、Transport等）
  - [x] 在AppWorkspace中添加开发模式测试入口，可通过按钮切换到AI SDK测试模式

- [x] **1.1.2 自定义Transport实现**
  - [x] 创建`src/lib/tauri-http-transport.ts`：基于标准fetch API的Transport
  - [x] 实现SSE流式响应的解析和处理逻辑
  - [x] 处理错误、重试等网络异常情况
  - [x] 实现ChatTransport接口要求的sendMessages/reconnectToStream方法
  - [x] 更新演示组件以使用自定义Transport，通过TauriHttpTransport进行测试

- [x] **1.1.3 基础连通性测试**
  - [x] ✅ **重大突破** - 端到端集成成功！
  - [x] 创建并测试`/chat/agent-stream`端点，完美支持AI SDK v5格式
  - [x] 验证LM Studio + gemma-3n-e4b-it模型正确响应
  - [x] 确认SSE流式响应格式完全符合AI SDK v5规范
  - [x] 测试结果：前端Transport → 后端SSE → 模型响应 → 流式文本显示 ✅

### 1.2 后端SSE兼容改造（风险2解决）

- [x] **1.2.1 FastAPI SSE端点创建**
  - [x] 在`models_api.py`中创建`/chat/agent-stream`端点
  - [x] 支持AI SDK v5的UIMessage格式解析
  - [x] 实现SSE (Server-Sent Events) 流式响应
  - [x] 设置正确的CORS头和Cache-Control策略
  - [x] 集成系统配置的模型选择（LM Studio + gemma-3n-e4b-it）

### 1.3 端到端集成测试

- [x] **1.3.1 Backend SSE流式验证**
  - [x] 修复litellm异步迭代器兼容性问题（CustomStreamWrapper错误）
  - [x] 修复JSON变量作用域冲突问题
  - [x] 验证LM Studio模型(gemma-3n-e4b-it)正确响应
  - [x] 确认SSE事件格式符合AI SDK v5规范（message-start、text-delta、message-end）
  
- [x] **1.3.2 Frontend Transport集成测试** ✅ **重大成功！**
  - [x] ✅ **完全成功** - 实现了真正的AI SDK v5集成（非mock）
  - [x] 弃用自定义Transport方案，采用AI SDK v5原生textStream模式
  - [x] 实现基于fetch + SSE的流式文本接收，完美支持打字机效果
  - [x] 集成Markdown渲染组件，支持完整的Markdown格式（代码块、表格、列表等）
  - [x] 实现实时滚动和字符级打字机效果（50ms延迟优化）
  - [x] 后端优化：按字符分割大chunks，提升打字机体验
  - [x] 错误处理完善：网络异常、流式中断、JSON解析错误
  - [x] 测试验证：端到端聊天 → 流式响应 → Markdown渲染 → 打字机效果 ✅

### 1.4 架构突破与最终实现

- [x] **1.4.1 AI SDK v5正确集成模式** 🎯 **核心突破**
  - [x] 发现并实现AI SDK v5的textStream正确用法
  - [x] 摒弃复杂的自定义Transport，使用原生fetch + ReadableStream
  - [x] 实现符合AI SDK v5文档的流式处理：`for await (const textPart of result.textStream)`
  - [x] 建立清晰的架构：Frontend fetch → Backend SSE → Model stream → 打字机渲染

- [x] **1.4.2 用户体验完善** 🎨 **体验优化**
  - [x] 集成高质量Markdown渲染（react-markdown + remark-gfm + shiki语法高亮）
  - [x] 实现平滑打字机效果（字符级流式 + 50ms延迟）
  - [x] 自动滚动到底部，保持对话连续性
  - [x] 用户消息纯文本，AI消息Markdown渲染的差异化体验
  - [x] 完善的加载状态：思考中 → 打字机光标 → 完成状态

- [x] **1.4.3 技术栈最终确定** 📚 **架构清理**
  - [x] 删除所有测试组件和mock代码
  - [x] 移除不必要的自定义Transport文件
  - [x] 简化AppWorkspace为统一聊天界面
  - [x] 建立干净的组件架构：AppWorkspace → AiSdkChat → MarkdownContent

---

## 🗄️ 第二阶段：数据库设计与API完善（P1 - 重要功能）

**目标**：建立完整的对话状态管理和会话持久化系统

### 2.1 数据库架构设计

- [x] **2.1.1 会话管理表设计**
- [x] **2.1.2 消息存储表设计**
- [x] **2.1.3 会话文件关联表设计**

见db_mgr.py

### 2.2 会话管理API开发

- [x] **2.2.1 会话CRUD端点**
  - [x] `POST /chat/sessions` - 创建新会话（自动生成智能名称）
  - [x] `GET /chat/sessions` - 获取会话列表（支持分页和搜索）
  - [x] `PUT /chat/sessions/{id}` - 更新会话信息（重命名等）
  - [x] `DELETE /chat/sessions/{id}` - 软删除会话

- [x] **2.2.2 消息持久化端点**
  - [x] `GET /chat/sessions/{id}/messages` - 获取会话消息（支持分页、最近30条优先）
  - [x] `POST /chat/sessions/{id}/messages` - 批量保存消息
  - [x] 在`/chat/agent-stream`端点中集成自动消息保存逻辑

- [x] **2.2.3 会话文件管理端点**
  - [x] `GET /chat/sessions/{id}/pinned-files` - 获取会话Pin文件列表
  - [x] `POST /chat/sessions/{id}/pin-file` - 为会话Pin文件
  - [x] `DELETE /chat/sessions/{id}/pinned-files/{file_id}` - 取消Pin文件
  - [x] 文件状态变更的实时同步机制

### 2.3 智能上下文管理实现

- [ ] **2.3.1 动态上下文截断机制**
  - [ ] 实现基于token限制的智能消息截断算法
  - [ ] 优先级策略：`系统prompt > 最新消息 > pin文件context > 历史消息`
  - [ ] 支持不同模型的不同上下文窗口大小

- [ ] **2.3.2 会话状态恢复机制**
  - [ ] 实现UIMessage数组的高效序列化/反序列化
  - [x] 会话切换时的状态恢复：pin文件列表 + 聊天记录
  - [ ] 处理大会话的性能优化：增量加载、虚拟滚动

---

## 🎨 第三阶段：前端UI完善与用户体验（P2 - 体验优化）

**目标**：完善聊天界面的交互体验和视觉设计

### 3.1 Chat组件重构与集成

- [ ] **3.1.1 基于Vercel AI SDK UI的'AI Elements'组件**
  - [ ] 使用新的useChat hook重构现有聊天界面
  - [ ] 实现类型安全的消息渲染逻辑（文本、工具调用、数据部分）
  - [ ] 

- [x] **3.1.2 会话管理UI**
  - [x] 实现会话列表侧边栏（类似ChatGPT体验）
  - [x] 会话创建、重命名、删除的用户交互
  - [x] 会话切换时的平滑过渡和状态恢复

- [x] **3.1.3 Pin文件管理UI集成**
  - [x] 在聊天界面显示当前会话的Pin文件列表
  - [x] 文件Pin/UnPin的快捷操作
  - [x] 文件向量化状态的可视化反馈

### 3.2 用户体验优化

- [ ] **3.2.1 智能状态指示**
  - [ ] 模型状态指示器：在线模型 vs 本地模型
  - [ ] 网络状态监控和降级提示
  - [ ] 消息发送状态：发送中、已送达、失败重试

- [ ] **3.2.2 交互体验增强**
  - [ ] 消息操作：复制、重新生成、编辑、删除
  - [ ] 聊天记录的无限滚动和性能优化
  - [ ] 快捷键支持：发送、换行、切换会话等

---

## 📊 里程碑和验收标准

### 第一阶段完成标准（技术验证）✅ **已完成 - 2025年8月6日**

- ✅ **环境适配成功**：在Tauri环境中AI SDK v5正常工作，无类型错误
- ✅ **网络连通性**：基于fetch + SSE的流式响应稳定工作，完全符合AI SDK v5规范
- ✅ **基础对话**：用户发送消息 → 模型响应 → 实时打字机显示，完整链路通畅
- ✅ **Markdown渲染**：完整支持代码块、表格、列表等格式，提供高质量阅读体验
- ✅ **用户体验**：50ms字符级打字机效果，自动滚动，完善的加载状态
- ✅ **架构简洁**：弃用复杂Transport方案，采用AI SDK v5原生模式，代码清晰可维护

> **重要里程碑**：第一阶段不仅完成了所有预定目标，还超额实现了Markdown渲染和优化的用户体验。技术验证阶段宣告**完全成功**！

### 第二阶段完成标准（功能完整）- 🎯 下一阶段目标

- [x] **会话管理**：创建、切换、删除会话功能完整可用
- [x] **状态恢复**：会话切换时Pin文件列表和聊天记录正确恢复
- [ ] **智能上下文**：动态token截断机制正常工作，对话连贯性良好
- [x] **数据持久化**：所有聊天数据安全保存，应用重启后完整恢复

### 第三阶段完成标准（用户体验）- 🎨 未来规划

- [ ] **界面流畅**：聊天界面响应迅速，交互逻辑清晰直观
- [ ] **状态感知**：用户能清楚了解当前使用的模型和网络状态
- [ ] **错误处理**：各种异常场景都有合理的用户提示和恢复机制

---

## 🔧 技术实现要点

### 关键技术选择

- **前端框架**：React + TypeScript + Vercel AI SDK v5
- **状态管理**：AI SDK内置状态 + 自定义Transport
- **网络层**：Tauri HTTP API + SSE协议
- **后端框架**：FastAPI + sse-starlette
- **数据库**：SQLite（轻量级、本地化）
- **消息格式**：UIMessage（AI SDK v5标准）

### 性能优化策略

- **消息分页**：虚拟滚动 + 增量加载
- **上下文管理**：智能截断 + 优先级排序
- **缓存策略**：会话列表 + 消息历史本地缓存
- **网络优化**：请求去重 + 连接复用

### 扩展性考虑

- **RAG集成预留**：消息表sources字段，支持未来检索来源记录
- **多模态支持**：UIMessage parts结构支持文本、图像、工具调用等
- **插件机制**：Transport层可扩展，支持不同协议和提供商
- **国际化准备**：用户界面文本外部化，支持多语言

---

## 🎯 下一步行动

### 第一阶段总结 ✅ **重大成功 - 2025年8月6日**

经过深入的技术探索和迭代，我们实现了以下重大突破：

1. **技术架构突破**：
   - 发现AI SDK v5的正确使用模式，弃用复杂的自定义Transport
   - 实现基于原生fetch + SSE的简洁架构
   - 建立清晰的数据流：Frontend → Backend SSE → Model Stream → UI Render

2. **用户体验突破**：
   - 实现平滑的字符级打字机效果（50ms延迟优化）
   - 集成完整的Markdown渲染支持（代码高亮、表格、列表等）
   - 后端字符级chunk分割，提升流式体验的流畅度

3. **代码质量突破**：
   - 删除所有测试代码和mock实现
   - 建立干净、可维护的组件架构
   - 实现完善的错误处理和状态管理

### 第二阶段规划 🎯 **接下来的目标**

基于第一阶段的成功，现在可以自信地进入第二阶段：

1. **确认技术方案**：✅ AI SDK v5集成方案已经完全验证，可作为后续开发的坚实基础
2. **数据库设计**：开始设计会话管理和消息持久化的数据结构
3. **API开发**：基于已验证的流式聊天端点，扩展会话管理API
4. **定期Review**：建立迭代节奏，保持高质量交付

> **关键成就**：我们不仅解决了最初担心的技术风险，还建立了一个高质量、用户体验优秀的聊天系统基础。第一阶段的**超额完成**为整个项目奠定了坚实基础！
> **注意**：本文档将随着开发进展持续更新，记录实际实现中的发现和调整。所有设计决策都基于当前需求，支持未来的渐进式增强。
