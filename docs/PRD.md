# 产品需求文档

在人工智能时代数据的重要性不言而喻，而对于普通人来说个人数据几乎都是文件的方式保存在电脑中，
怎么利用强大的人工智能在线模型来帮助用户挖掘和利用这些文件中的知识呢？就需要一款桌面端App。另外还有一些理由和趋势：

- 个人隐私保护：越来越多的人关注个人隐私和数据安全，担心将敏感信息上传到云端。
- 个人电脑的算力不够，无法支持大型模型的运行，但可以通过本地应用程序与云端服务进行交互，同时它可以直接访问用户的文件系统，避免了上传和下载的麻烦。
- 用户积累的文件可能被遗忘在某个角落，难以被重新发现和利用。用户希望能有机制在做新的事情时把过往知识也利用起来，低成本地重新发现和利用。
- 一些AIPC厂商在营销中强调新硬件的算力提升，但实际上用户使用的都是在线模型，销售卖点并不成立，因为他们没找到合适场景和产品来利用这些算力。
总之用户希望在数据隐私、持续数据积累和利用、更先进的人工智能技术的使用方面达到一个好的平衡。从产业看，模型小型化、边缘计算、云与端协同、自主操控电脑的智能体均是趋势。

本产品设计目标是帮助用户发现和利用电脑中保存在各类文档中的知识，名字叫作“知识焦点”(Knowledge Focus)，是全平台桌面客户端App。

功能概述：在用户的授权下读取保存有用户有感知的、作为知识载体的文件，所谓有感知的文件是指用户知道这些文件的存在和价值，通常是在各类软件的明确要求下保存的文件。全面扫描加后续监控，结合共读和对话的交互行为，帮助用户积累知识库。

## 文件扫描和文件变化感知系统

本App会在用户授权的情况下，预先扫描用户电脑上的文件系统，读取文件的元数据(如路径、大小、时间戳等)，并根据文件名、扩展名等信息进行初步分类。
本App会持续监控已授权文件夹的变化，及时更新文件的元数据和标签信息，并推动进行后续数据加工。

## 动态标签系统

本App会根据文件名、文件所在路径中的信息、文件内容、元数据中时间类信息等为文件打上多个标签，以便用户更方便地进行搜索和后续的知识抽取和利用。
标签都是有语义的，语义范围也体现了对文件价值描述的不同颗粒度。可以用来快速对本机所有文件进行预先筛选，缩小范围后在技术上能更好的支持后续对话和知识抽取。
标签由几种来源：

- 本App预设标签：项目、重要、旅行、汇报、论文等，作为LLM给文件打标签的参考。
- 用户自定义标签：用户可以在App中添加、修改、删除标签，标签的语义范围由用户决定。
- LLM生成的标签：体现LLM智能的一点就是不断在跟用户的对话中发现、积累、评估后使用已有标签或新创标签，体现了人工智能时代的产品特性。

## 多模态检索系统

本App将支持多种文件类型的检索，包括文本、图片、音频、视频等。通过对不同类型文件的内容进行分析和索引，用户可以更方便地进行跨文件、跨类型的知识检索。然后传递给“最”先进的在线商业模型进行处理。
无论是动态标签系统还是多模态检索系统，其中模型的小型化、专用化、本地化可以更好地理解和利用这些文件中的知识，也迎合了用户对隐私保护和数据安全的需求。
通过使用Docling库进行文字、表格、图像分拆后分别进行摘要和描述，最后进行纯文本向量化。召回给大模型的是原始文本和原始图像，以便多模态大模型在不遗失任何细节的情况下进行答案合成

## 桌面智能体系统

运用桌面App特有的可以“辅助控制”其他App的优势，观察其他App的内容和行为，通过发送键盘鼠标事件来控制其他App，帮助用户完成一些重复性、机械性的任务，提高工作效率。这是其他基于浏览器的Web App无法实现的功能。
官方第一个智能体应用是“共读”，用户可以选择某个文件(如电子书、报告、PPT等)进行精读，App会通过视觉大模型和多模态检索系统感知用户事业和整个文件内容，并结合用户的阅读习惯和偏好，提供个性化的阅读建议和辅助功能。

## 技术流程设计

在这个Tauri App中，是三种语言混合使用：

- TypeScript负责前端界面呈现和交互逻辑。
- Rust直接跟操作系统打交道，做文件查找和扫描等。
- Python负责处理数据和跟数据库打交道，也负责调用LLM。

技术流程概述：

1. 前端TypeScript跟Python API配合，按照Windows和macOS不同常用文件夹列表，通过“完全磁盘访问权限”请求用户授权。
2. Rust的“粗筛(screening)”工作
   1. 读取文件元数据(路径、大小、时间戳、计算基本哈希，注意这阶段并不读取文件内容)，进行初步规则匹配(如扩展名分类、简单文件名模式等等)。
   2. 将更结构化的任务信息(包含元数据和初步分类结果)通过Python API入库到粗筛结果表。
3. Python的“打标签(tagging)”工作，此过程使用的较少的资源和时间
   1. Rust向任务表插入记录，Python的worker从粗筛结果表拿到相关数据。
   2. 使用markitdown对其支持的文件格式进行解析，虽然它会丢失图片信息，但单纯文本内容的解析和标签生成是可行的。
   3. 使用LLM利用粗筛数据和解析后的内容进行标签的生成，保存到标签库。考虑到执行效率和LLM上下文窗口限制，不用将完整内容给到LLM。
4. “多模态检索(multi-modal retrieval)”工作是人机交互过程的一部分。在用户“pin”文件之后再进行向量化，省去预先做大量无用工作的时间
   1. 用户在对话过程中使用来自pin在文件列表区的文件中的向量化知识。
   2. 用户在前端界面上可以选择哪些对话内容是可以进一步加工后沉淀到知识库。
   3. “共读”是针对某一文件的交互式精读(电子书/报告/PPT等)，在技术上跟“非共读”的对话比，上下文设置以及使用的工具均有所区别。
5. Rust端作为前端TypeScript和后端Python FastAPI的“统一桥接器”
   1. 前端向后端发起的请求，经由Rust处理和中转，尤其对敏感的各类API key。
   2. Python端的任务处理结果(包括进度情况)通过Rust监控其stdout方式拿到，并通过Tauri的IPC机制传递给前端TypeScript。

总之，这种三方协同的设计兼顾了性能和质量：

- Rust擅长做OS级开发，有高性能的I/O能力，本身也是Tauri的核心语言
  - App启动后能迅速对用户已授权文件夹进行全面扫描，生成文件元数据。
  - 持续监控文件夹文件变化，对于频繁变更的文件元数据进行规则处理筛选后，传递给Python的任务量大大减少，减少了后续计算压力。
- Python的数据、AI生态强大
  - 对文件内容做粗放的解析(仅用markitdown快速处理，遗失一些信息也无妨)，生成标签，以便在精炼过程前筛选并缩小文件范围。
  - Python在同用户的交互过程中对文件进行详细的解析和提取，形成高质量的知识片段(知识卡片)。
- 以React为前端框架，能利用很多UI组件库和生态，提升美感，提升开发效率。
  - 使用TypeScript为开发语言
  - 使用shadcn(radix-ui+tailwindcss)
  - 使用tweakcn为多theme支持

## 日常开发备忘

- `tauri-app/dev.sh`: Start the development server
- `tauri-app/build.sh`: Build the application (TypeScript compilation + Vite build)
- `api/`: Python backend for file and database management. `api_standalone.sh` for standalone mode, need activate conda env first by `conda activate ./.venv`
- `~/Library/Application\ Support/knowledge-focus.huozhong.in`: Default data directory on macOS, where the application stores its data files `knowledge-focus.db`, MCP tool 'SQLite' can be used to access it.
- `~/Library/Application\ Support/knowledge-focus.huozhong.in/logs/*.log`: Log files for the Python API, useful for debugging and monitoring

## 总结

这是一个从粗筛到精炼的三级数据质量体系。

1. 最初通过文件全路径(主文件名，扩展名，路径内的语义信息)快速进行粗筛，圈定用户有明确感知的携带了知识的文件。
2. 接着通过对文件内容的粗放解析，生成语义覆盖范围大的标签，帮助用户快速定位和筛选文件。
3. 最后，通过用户交互和LLM的智能处理，对文件内容进行深入解析和知识卡片的生成。

用户通过共读和对话的方式将自身认知、LLM模型内知识、文件内知识和外部世界知识(调用搜索工具等)进行整合和精炼，形成了用户有感知、有印象的知识库的积累。
